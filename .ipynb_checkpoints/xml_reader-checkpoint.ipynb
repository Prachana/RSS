{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import csv\n",
    "from os import path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file():\n",
    "    existing_accession = []\n",
    "\n",
    "    coumn_name = ['Submmission type','Amendment','Withdrawl',\n",
    "              'Filing Data','Central Index Key', 'Filer name','Filder Phone','Filer Email',\n",
    "                'Aplicant Firstname','Applicant Middlename','Applicant Lastname',\n",
    "                'Firm Name', 'Employment Date','Relatioship to Firm',\n",
    "                'File Number','Start Date', 'Street_1','Street_2','City','State','Zipcode','Accession Number',]\n",
    "    \n",
    "    if path.exists('filings.csv'):\n",
    "        with open('filings.csv') as file:\n",
    "            read = csv.reader(file,delimiter=',')\n",
    "            next(read)\n",
    "            for i in read:\n",
    "                if not ''.join(i).strip():\n",
    "                    continue\n",
    "                existing_accession.append(i[-1])\n",
    "            file.close()\n",
    "    else:\n",
    "        \n",
    "        df = pd.DataFrame(columns=coumn_name,index=None)\n",
    "        df.to_csv(\"filings.csv\",index=None)\n",
    "        print(\"Filings.csv created\")\n",
    "        \n",
    "    \n",
    "    return existing_accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000072468320000006',\n",
       " '000072468320000005',\n",
       " '000072468320000007',\n",
       " '000072468320000008',\n",
       " '000072468320000009',\n",
       " '000179415419000002',\n",
       " '000161106019000004',\n",
       " '000072468320000003',\n",
       " '000072468320000002',\n",
       " '000161435119000005',\n",
       " '000072474320000001',\n",
       " '000161779320000001',\n",
       " '000009440320000002',\n",
       " '000085571320000002',\n",
       " '000175522719000014',\n",
       " '000175522719000015',\n",
       " '000076999319000591',\n",
       " '000160419720000001',\n",
       " '000108655519000003',\n",
       " '000161699519000103',\n",
       " '000161699519000104',\n",
       " '000161699519000105',\n",
       " '000161699519000106',\n",
       " '000076999320000001',\n",
       " '000076999320000002',\n",
       " '000076999319000592',\n",
       " '000076999319000593',\n",
       " '000076999319000594',\n",
       " '000108655519000004',\n",
       " '000108655519000005',\n",
       " '000161372419000004',\n",
       " '000076999319000595',\n",
       " '000161242919000023',\n",
       " '000161717719000004',\n",
       " '000009440320000001',\n",
       " '000164036720000002',\n",
       " '000085571320000001',\n",
       " '000170051120000002',\n",
       " '000174470220000001',\n",
       " '000177308320000003',\n",
       " '000166951720000001',\n",
       " '000166951720000002',\n",
       " '000166951720000003',\n",
       " '000166951720000004',\n",
       " '000166951720000005',\n",
       " '000166951720000006',\n",
       " '000166951720000007',\n",
       " '000161477420000003',\n",
       " '000161477420000004',\n",
       " '000009440320000004',\n",
       " '000162399720000001',\n",
       " '000162399720000002',\n",
       " '000161477420000001',\n",
       " '000161477420000002',\n",
       " '000161395620000001',\n",
       " '000009440320000003',\n",
       " '000162907020000002']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssfeed(rsslink):\n",
    "    htm_links = []\n",
    "    xml_links = []\n",
    "    accession = []\n",
    "    \n",
    "    \n",
    "    feeds = feedparser.parse(rsslink)\n",
    "    entry = feeds.entries\n",
    "    #get HTML link\n",
    "    for htm in entry:\n",
    "        htm_links.append(htm.link)\n",
    "    #print(htm_links)\n",
    "    \n",
    "    for i in htm_links:\n",
    "        txt = i.split(\"/\")[:-1]\n",
    "        txt.append('primary_doc.xml')\n",
    "        joined = '/'.join(txt)\n",
    "        xml_links.append(joined)\n",
    "    for acc in htm_links:\n",
    "        number = acc.split(\"/\")[-2]\n",
    "        accession.append(number)\n",
    "       \n",
    "    exisiting = check_file()  \n",
    "     \n",
    "    indx  = np.where(np.in1d(accession,exisiting))[0]\n",
    "    \n",
    "    for i in indx:\n",
    "        xml_links.pop()\n",
    "        accession.pop()\n",
    "    \n",
    "    return xml_links, accession\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rssfeed('https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent&CIK=&type=MA-I&company=&dateb=&owner=include&start=0&count=100&output=atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction():\n",
    "    xml_list,acc = rssfeed('https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent&CIK=&type=MA-I&company=&dateb=&owner=include&start=0&count=100&output=atom')\n",
    "    if not xml_list:\n",
    "        print(\"No New filings\")\n",
    "    else:\n",
    "        listing = []\n",
    "        accession = []\n",
    "        print(listing)\n",
    "\n",
    "        for bs_url in xml_list:\n",
    "            source = urllib.request.urlopen(bs_url)\n",
    "            soup = (bs.BeautifulSoup(source,'lxml'))\n",
    "            header = soup.find_all('headerdata')\n",
    "            for sub_Type in header:\n",
    "                submmission_type = sub_Type.find('submissiontype').text\n",
    "\n",
    "            form_data = soup.find_all('formdata')\n",
    "            for data in form_data:\n",
    "                amendment = data.find('isamendment').text\n",
    "                withdrawl = data.find('isindividual').text\n",
    "                file_date = data.find('com:datesigned').text\n",
    "\n",
    "                if data.find('com:title') == None:\n",
    "                    title =\"N/A\"\n",
    "                else:\n",
    "                    title = data.find('com:title').text \n",
    "\n",
    "            filer_info = soup.find_all('filerinfo')\n",
    "            for filer in filer_info:\n",
    "                fid = filer.find('com1:filerid').text\n",
    "                filer_name = filer.find('com1:name').text\n",
    "                filer_phone = filer.find('com1:phonenumber').text\n",
    "                filer_email = filer.find('com:contactemail').text\n",
    "\n",
    "            applicant_info = (soup.find_all('applicantname'))\n",
    "            for applicant in applicant_info:\n",
    "                applicant_name = applicant.find('com:firstname').text\n",
    "                applicant_M_name = applicant.find('com:middlename').text\n",
    "                applicant_L_name = applicant.find('com:lastname').text\n",
    "\n",
    "            muni_office = (soup.find_all('municipaladvisoroffices'))\n",
    "            for office in muni_office:\n",
    "                municipal_firmname = office.find('municipalfirmname').text\n",
    "                employment_date = office.find('recentemploymentcommenceddate').text\n",
    "                relatioship = office.find('isindependentrelatioship').text\n",
    "\n",
    "                if office.find('com:filenumber') == None:\n",
    "                    file_number = \"N/A\"\n",
    "                else:\n",
    "                    file_number = office.find('com:filenumber').text\n",
    "\n",
    "                star_date = office.find('startdate').text\n",
    "\n",
    "                if office.find('com1:street1') == None:\n",
    "                    street_1 = \"N/A\"\n",
    "                else:            \n",
    "                    street_1 = office.find('com1:street1').text\n",
    "\n",
    "                if office.find('com1:street2') == None:\n",
    "                    street_2 = \"N/A\"\n",
    "                else:\n",
    "                    street_2 = office.find('com1:street2').text\n",
    "\n",
    "\n",
    "                if office.find('com1:city') == None:\n",
    "                    city = \"N/A\"\n",
    "                else:\n",
    "                    city = office.find('com1:city').text\n",
    "\n",
    "                if office.find('com1:stateorcountry') == None:\n",
    "                    state = \"N/A\"\n",
    "                else:\n",
    "                    state = office.find('com1:stateorcountry').text\n",
    "\n",
    "                if office.find('com1:zipcode') == None:\n",
    "                    zipcode = \"N/A\"\n",
    "                else:\n",
    "\n",
    "                    zipcode = office.find('com1:zipcode').text\n",
    "                #print(municipal_firmname , employment_date,relatioship,file_number,star_date,street_1,street_2,city,state,zipcode)\n",
    "\n",
    "\n",
    "            listing.append([submmission_type,amendment,withdrawl,\n",
    "                                file_date,fid,filer_name,filer_phone,filer_email,\n",
    "                                applicant_name,applicant_M_name,applicant_L_name,\n",
    "                                municipal_firmname , employment_date,relatioship,\n",
    "                                file_number,star_date,street_1,street_2,city,state,zipcode])\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(listing,index=None)\n",
    "        df['Accession'] = acc\n",
    "\n",
    "        with open('filings.csv', 'a') as f:\n",
    "            df.to_csv(f,index=None,header=None)\n",
    "            f.close()\n",
    "        print(\"New Filings added to CSV\")\n",
    "  \n",
    "    return \"Complete\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No New filings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Complete'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
